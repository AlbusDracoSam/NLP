{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word Embedding.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOtbuna05H/LNKOKCSNf78D",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlbusDracoSam/NLP/blob/main/Word_Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39zaYJypo6in"
      },
      "source": [
        "**Word Embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laQrabWSorQR"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import one_hot\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dB_Z-B2pEjc"
      },
      "source": [
        "### sentences\n",
        "sent=[  'the glass of milk',\n",
        "     'the glass of juice',\n",
        "     'the cup of tea',\n",
        "    'I am a good boy',\n",
        "     'I am a good developer',\n",
        "     'understand the meaning of words',\n",
        "     'your videos are good',]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5bKf4jspPaE"
      },
      "source": [
        "vocab_size = 10000"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwSDWp9hpWyr"
      },
      "source": [
        "**One hot representation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_AkYAVopWDS",
        "outputId": "8224278e-0a17-45ad-a029-ba915d352041"
      },
      "source": [
        "onehot_representation = [one_hot(words, vocab_size) for words in sent]\n",
        "print(onehot_representation)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[8478, 8711, 6603, 8952], [8478, 8711, 6603, 9343], [8478, 4216, 6603, 4018], [7595, 7263, 7203, 5243, 2757], [7595, 7263, 7203, 5243, 3931], [3795, 8478, 447, 6603, 8222], [25, 7726, 9932, 5243]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5hGNry4vt6k"
      },
      "source": [
        "**Word Embedding Representation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fot9uFiMvwN0"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "import numpy as np"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDr9ryZiyDlg",
        "outputId": "e8ee6757-aa5f-435a-d520-f8a6db4174d5"
      },
      "source": [
        "sent_len = 8\n",
        "embedded = pad_sequences(onehot_representation, padding='pre', maxlen= sent_len)\n",
        "print(embedded)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0    0 8478 8711 6603 8952]\n",
            " [   0    0    0    0 8478 8711 6603 9343]\n",
            " [   0    0    0    0 8478 4216 6603 4018]\n",
            " [   0    0    0 7595 7263 7203 5243 2757]\n",
            " [   0    0    0 7595 7263 7203 5243 3931]\n",
            " [   0    0    0 3795 8478  447 6603 8222]\n",
            " [   0    0    0    0   25 7726 9932 5243]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77415wdOyq5V",
        "outputId": "cb5ab54e-1831-4fb2-c32b-cb4c35439922"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size,10,input_length=sent_len))\n",
        "model.compile('adam','mse')\n",
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 8, 10)             100000    \n",
            "=================================================================\n",
            "Total params: 100,000\n",
            "Trainable params: 100,000\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKJcaO40zORY",
        "outputId": "49668379-eb43-48db-8130-0a26e60ae9ee"
      },
      "source": [
        "print(model.predict(embedded))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[[-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.01225618  0.04945382 -0.03807765 -0.04166131 -0.00782003\n",
            "    0.01786743 -0.02905165 -0.04693104 -0.00578319 -0.00098543]\n",
            "  [ 0.00114057  0.01375045 -0.02427146 -0.02939487  0.01023847\n",
            "   -0.04116623 -0.02867766 -0.03412961 -0.00623561  0.0328499 ]\n",
            "  [-0.03457646  0.01117011 -0.04799024  0.04472161  0.03804269\n",
            "    0.0178959  -0.04861553  0.04949132  0.02964031  0.00326178]\n",
            "  [-0.03592153 -0.02876412  0.00319435 -0.02319703 -0.02046286\n",
            "    0.04366919 -0.02562406 -0.01019416 -0.03282271  0.02000513]]\n",
            "\n",
            " [[-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.01225618  0.04945382 -0.03807765 -0.04166131 -0.00782003\n",
            "    0.01786743 -0.02905165 -0.04693104 -0.00578319 -0.00098543]\n",
            "  [ 0.00114057  0.01375045 -0.02427146 -0.02939487  0.01023847\n",
            "   -0.04116623 -0.02867766 -0.03412961 -0.00623561  0.0328499 ]\n",
            "  [-0.03457646  0.01117011 -0.04799024  0.04472161  0.03804269\n",
            "    0.0178959  -0.04861553  0.04949132  0.02964031  0.00326178]\n",
            "  [-0.00260587 -0.03819171 -0.01892569  0.03534254  0.03593576\n",
            "    0.01339072  0.04272899  0.02288968  0.01344765  0.00583022]]\n",
            "\n",
            " [[-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.01225618  0.04945382 -0.03807765 -0.04166131 -0.00782003\n",
            "    0.01786743 -0.02905165 -0.04693104 -0.00578319 -0.00098543]\n",
            "  [ 0.03582035  0.01415752  0.02367986  0.02868129 -0.0416426\n",
            "   -0.02459949  0.01325747 -0.02753466  0.02815776  0.01180084]\n",
            "  [-0.03457646  0.01117011 -0.04799024  0.04472161  0.03804269\n",
            "    0.0178959  -0.04861553  0.04949132  0.02964031  0.00326178]\n",
            "  [ 0.03390891  0.03761565  0.00505579 -0.02152488 -0.02404237\n",
            "    0.03912753  0.03437248  0.03690049  0.03276983  0.00125699]]\n",
            "\n",
            " [[-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.02302153  0.02746104 -0.03546915 -0.00162701  0.03432956\n",
            "    0.03291601 -0.03819933  0.04339046 -0.04583749  0.00672736]\n",
            "  [-0.03505722  0.00142096 -0.0282584  -0.04666004 -0.00473665\n",
            "    0.04430424 -0.02405306  0.03841114  0.0219002  -0.01595948]\n",
            "  [ 0.00991543  0.01731504 -0.02711638  0.04169318  0.03440206\n",
            "   -0.03984977  0.0259526   0.01918223  0.04073429 -0.03843111]\n",
            "  [-0.04681165 -0.03496591  0.03781046 -0.01197065 -0.04306824\n",
            "    0.04147525 -0.033459   -0.01727552 -0.03325341 -0.04009415]\n",
            "  [ 0.03567402  0.00991181 -0.00892916 -0.03943262 -0.0257622\n",
            "   -0.02856286 -0.04532243 -0.0014379   0.04325115 -0.01023909]]\n",
            "\n",
            " [[-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.02302153  0.02746104 -0.03546915 -0.00162701  0.03432956\n",
            "    0.03291601 -0.03819933  0.04339046 -0.04583749  0.00672736]\n",
            "  [-0.03505722  0.00142096 -0.0282584  -0.04666004 -0.00473665\n",
            "    0.04430424 -0.02405306  0.03841114  0.0219002  -0.01595948]\n",
            "  [ 0.00991543  0.01731504 -0.02711638  0.04169318  0.03440206\n",
            "   -0.03984977  0.0259526   0.01918223  0.04073429 -0.03843111]\n",
            "  [-0.04681165 -0.03496591  0.03781046 -0.01197065 -0.04306824\n",
            "    0.04147525 -0.033459   -0.01727552 -0.03325341 -0.04009415]\n",
            "  [ 0.01309928  0.0008729  -0.0155239   0.0111379   0.02338703\n",
            "    0.04913275 -0.00453491 -0.04449408  0.00702548 -0.00059781]]\n",
            "\n",
            " [[-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.01738626  0.0116771   0.0246001  -0.02735726 -0.047642\n",
            "   -0.02400488  0.01872646 -0.00650517 -0.0250648  -0.0291513 ]\n",
            "  [-0.01225618  0.04945382 -0.03807765 -0.04166131 -0.00782003\n",
            "    0.01786743 -0.02905165 -0.04693104 -0.00578319 -0.00098543]\n",
            "  [-0.00025989 -0.00408671  0.03148809 -0.03421625  0.02346153\n",
            "   -0.00718583  0.04364605  0.02640558 -0.02627397  0.0390918 ]\n",
            "  [-0.03457646  0.01117011 -0.04799024  0.04472161  0.03804269\n",
            "    0.0178959  -0.04861553  0.04949132  0.02964031  0.00326178]\n",
            "  [-0.0378041  -0.03188278 -0.04428612 -0.01122785 -0.04151583\n",
            "   -0.00942651  0.01940319 -0.01337923 -0.0052579  -0.02933511]]\n",
            "\n",
            " [[-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]\n",
            "  [-0.03926564  0.00076932 -0.01281847  0.0092775   0.02881468\n",
            "    0.036194    0.02250662 -0.04614706 -0.0367929  -0.02558273]\n",
            "  [-0.03541923  0.0111622  -0.02367553 -0.0270968  -0.00906669\n",
            "   -0.0240625   0.00070622 -0.03683418 -0.04570326  0.00548699]\n",
            "  [ 0.01453372 -0.04625815 -0.03127116 -0.03979675 -0.00902734\n",
            "   -0.0115764  -0.02046505 -0.02305627 -0.01406892 -0.00673334]\n",
            "  [-0.04681165 -0.03496591  0.03781046 -0.01197065 -0.04306824\n",
            "    0.04147525 -0.033459   -0.01727552 -0.03325341 -0.04009415]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSf5hIG6zyvJ",
        "outputId": "b79fd81c-d19d-4a24-8390-e3cb6c39086d"
      },
      "source": [
        "print(model.predict(embedded[0]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 8) for input KerasTensor(type_spec=TensorSpec(shape=(None, 8), dtype=tf.float32, name='embedding_1_input'), name='embedding_1_input', description=\"created by layer 'embedding_1_input'\"), but it was called on an input with incompatible shape (None, 1).\n",
            "[[[-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]]\n",
            "\n",
            " [[-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]]\n",
            "\n",
            " [[-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]]\n",
            "\n",
            " [[-0.04409908  0.0126865   0.02530045  0.0052531  -0.02070138\n",
            "    0.00143424  0.02769703 -0.03703167  0.01522293  0.01235937]]\n",
            "\n",
            " [[-0.01225618  0.04945382 -0.03807765 -0.04166131 -0.00782003\n",
            "    0.01786743 -0.02905165 -0.04693104 -0.00578319 -0.00098543]]\n",
            "\n",
            " [[ 0.00114057  0.01375045 -0.02427146 -0.02939487  0.01023847\n",
            "   -0.04116623 -0.02867766 -0.03412961 -0.00623561  0.0328499 ]]\n",
            "\n",
            " [[-0.03457646  0.01117011 -0.04799024  0.04472161  0.03804269\n",
            "    0.0178959  -0.04861553  0.04949132  0.02964031  0.00326178]]\n",
            "\n",
            " [[-0.03592153 -0.02876412  0.00319435 -0.02319703 -0.02046286\n",
            "    0.04366919 -0.02562406 -0.01019416 -0.03282271  0.02000513]]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}